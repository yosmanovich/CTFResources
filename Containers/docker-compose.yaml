services:
  ollama:    
    container_name: ollama
    image: ${acrName}/ollama:ollama
    build:
      context: .
      dockerfile: ollama-Dockerfile
    ports:
      - 11434:11434
    volumes:
      - ollama-data:/root/.ollama      
    environment:
       - OLLAMA_HOST=0.0.0.0:11434      
    restart: unless-stopped        
    networks:
      - internal-network

  ollama-proxy:
    container_name: ollama-proxy
    image: ${acrName}/ollama-proxy:ollama-proxy    
    restart: always
    build:
      context: .
      dockerfile: ollama-proxy-Dockerfile
    environment:
      USER_KEY: "a"
      ADMIN_KEY: "b"
      OLLAMA_BASE_URL: http://ollama:11434
    ports:
      - 80:80
    networks:
      - internal-network
      - external-network

  ollama-gui:
    container_name: ollama-gui
    image: ${acrName}/ollama-gui:ollama-gui
    restart: always
    build:
      context: .
      dockerfile: ollama-gui-Dockerfile
    ports:
      - 8080:8080
    volumes:
       - openwebui-data:/app/backend/data
    environment:
       - OLLAMA_BASE_URL=http://ollama:11434       
    extra_hosts:
       - "host.docker.internal:host-gateway"
    networks:
      - internal-network     
      - external-network

  ollama-chainlit:
    container_name: chainlit
    image: ${acrName}/chainlit:chainlit
    restart: always
    build:
      context: .
      dockerfile: chainlit-Dockerfile
    environment:
      - API_KEY=FAKE_KEY
      - BASE_URL=http://ollama:11434/v1
      - MODEL=TinyLlama:latest
    ports:
      - 8081:8081
    networks:
      - internal-network     
      - external-network

volumes:
  ollama-data:
    name: ollama-data
  openwebui-data:
    name: openwebui-data    

networks:
  external-network:
    name: external-network
    external: true
  internal-network:
    name: internal-network